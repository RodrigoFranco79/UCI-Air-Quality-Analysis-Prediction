{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3b14752",
   "metadata": {},
   "outputs": [],
   "source": [
    " df = pd.read_csv(\"/Users/Gunnar/Documents/GitHub/UCI-Air-Quality-Analysis-Prediction/input/AirQualityUCI.csv\", parse_dates={'datetime': ['Date', 'Time']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3d3154e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>CO_GT</th>\n",
       "      <th>PT08_S1_CO</th>\n",
       "      <th>NMHC_GT</th>\n",
       "      <th>C6H6_GT</th>\n",
       "      <th>PT08_S2_NMHC</th>\n",
       "      <th>Nox_GT</th>\n",
       "      <th>PT08_S3_Nox</th>\n",
       "      <th>NO2_GT</th>\n",
       "      <th>PT08_S4_NO2</th>\n",
       "      <th>PT08_S5_O3</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>CO_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-11-23 19:00:00</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2008</td>\n",
       "      <td>-200</td>\n",
       "      <td>50.6</td>\n",
       "      <td>1980</td>\n",
       "      <td>1389</td>\n",
       "      <td>325</td>\n",
       "      <td>220</td>\n",
       "      <td>2562</td>\n",
       "      <td>2342</td>\n",
       "      <td>12.4</td>\n",
       "      <td>74.7</td>\n",
       "      <td>1.0741</td>\n",
       "      <td>Very High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-11-23 20:00:00</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1918</td>\n",
       "      <td>-200</td>\n",
       "      <td>49.4</td>\n",
       "      <td>1958</td>\n",
       "      <td>1358</td>\n",
       "      <td>335</td>\n",
       "      <td>190</td>\n",
       "      <td>2477</td>\n",
       "      <td>2237</td>\n",
       "      <td>11.5</td>\n",
       "      <td>76.2</td>\n",
       "      <td>1.0324</td>\n",
       "      <td>Very High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-11-17 18:00:00</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1802</td>\n",
       "      <td>-200</td>\n",
       "      <td>47.7</td>\n",
       "      <td>1924</td>\n",
       "      <td>748</td>\n",
       "      <td>356</td>\n",
       "      <td>192</td>\n",
       "      <td>2235</td>\n",
       "      <td>2452</td>\n",
       "      <td>13.7</td>\n",
       "      <td>52.8</td>\n",
       "      <td>0.8244</td>\n",
       "      <td>Very High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-11-23 18:00:00</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1982</td>\n",
       "      <td>-200</td>\n",
       "      <td>49.5</td>\n",
       "      <td>1959</td>\n",
       "      <td>1369</td>\n",
       "      <td>322</td>\n",
       "      <td>227</td>\n",
       "      <td>2536</td>\n",
       "      <td>2386</td>\n",
       "      <td>13.2</td>\n",
       "      <td>72.6</td>\n",
       "      <td>1.0936</td>\n",
       "      <td>Very High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-11-26 18:00:00</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1956</td>\n",
       "      <td>-200</td>\n",
       "      <td>45.2</td>\n",
       "      <td>1877</td>\n",
       "      <td>1389</td>\n",
       "      <td>347</td>\n",
       "      <td>255</td>\n",
       "      <td>2338</td>\n",
       "      <td>2465</td>\n",
       "      <td>15.5</td>\n",
       "      <td>62.8</td>\n",
       "      <td>1.0979</td>\n",
       "      <td>Very High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9352</th>\n",
       "      <td>2005-03-23 04:00:00</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>993</td>\n",
       "      <td>-200</td>\n",
       "      <td>2.3</td>\n",
       "      <td>604</td>\n",
       "      <td>85</td>\n",
       "      <td>848</td>\n",
       "      <td>65</td>\n",
       "      <td>1160</td>\n",
       "      <td>762</td>\n",
       "      <td>14.5</td>\n",
       "      <td>66.4</td>\n",
       "      <td>1.0919</td>\n",
       "      <td>Very low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9353</th>\n",
       "      <td>2005-03-26 04:00:00</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>1122</td>\n",
       "      <td>-200</td>\n",
       "      <td>6.0</td>\n",
       "      <td>811</td>\n",
       "      <td>181</td>\n",
       "      <td>641</td>\n",
       "      <td>92</td>\n",
       "      <td>1336</td>\n",
       "      <td>1122</td>\n",
       "      <td>16.2</td>\n",
       "      <td>71.2</td>\n",
       "      <td>1.3013</td>\n",
       "      <td>Very low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354</th>\n",
       "      <td>2005-03-29 04:00:00</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>883</td>\n",
       "      <td>-200</td>\n",
       "      <td>1.3</td>\n",
       "      <td>530</td>\n",
       "      <td>63</td>\n",
       "      <td>997</td>\n",
       "      <td>46</td>\n",
       "      <td>1102</td>\n",
       "      <td>617</td>\n",
       "      <td>13.7</td>\n",
       "      <td>68.2</td>\n",
       "      <td>1.0611</td>\n",
       "      <td>Very low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>2005-04-01 04:00:00</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>818</td>\n",
       "      <td>-200</td>\n",
       "      <td>0.8</td>\n",
       "      <td>473</td>\n",
       "      <td>47</td>\n",
       "      <td>1257</td>\n",
       "      <td>41</td>\n",
       "      <td>898</td>\n",
       "      <td>323</td>\n",
       "      <td>13.7</td>\n",
       "      <td>48.8</td>\n",
       "      <td>0.7606</td>\n",
       "      <td>Very low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>2005-04-04 04:00:00</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>864</td>\n",
       "      <td>-200</td>\n",
       "      <td>0.8</td>\n",
       "      <td>478</td>\n",
       "      <td>52</td>\n",
       "      <td>1116</td>\n",
       "      <td>43</td>\n",
       "      <td>958</td>\n",
       "      <td>489</td>\n",
       "      <td>11.8</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.7743</td>\n",
       "      <td>Very low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9357 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime  CO_GT  PT08_S1_CO  NMHC_GT  C6H6_GT  PT08_S2_NMHC  \\\n",
       "0    2004-11-23 19:00:00   11.9        2008     -200     50.6          1980   \n",
       "1    2004-11-23 20:00:00   11.5        1918     -200     49.4          1958   \n",
       "2    2004-11-17 18:00:00   10.2        1802     -200     47.7          1924   \n",
       "3    2004-11-23 18:00:00   10.2        1982     -200     49.5          1959   \n",
       "4    2004-11-26 18:00:00   10.1        1956     -200     45.2          1877   \n",
       "...                  ...    ...         ...      ...      ...           ...   \n",
       "9352 2005-03-23 04:00:00 -200.0         993     -200      2.3           604   \n",
       "9353 2005-03-26 04:00:00 -200.0        1122     -200      6.0           811   \n",
       "9354 2005-03-29 04:00:00 -200.0         883     -200      1.3           530   \n",
       "9355 2005-04-01 04:00:00 -200.0         818     -200      0.8           473   \n",
       "9356 2005-04-04 04:00:00 -200.0         864     -200      0.8           478   \n",
       "\n",
       "      Nox_GT  PT08_S3_Nox  NO2_GT  PT08_S4_NO2  PT08_S5_O3     T    RH  \\\n",
       "0       1389          325     220         2562        2342  12.4  74.7   \n",
       "1       1358          335     190         2477        2237  11.5  76.2   \n",
       "2        748          356     192         2235        2452  13.7  52.8   \n",
       "3       1369          322     227         2536        2386  13.2  72.6   \n",
       "4       1389          347     255         2338        2465  15.5  62.8   \n",
       "...      ...          ...     ...          ...         ...   ...   ...   \n",
       "9352      85          848      65         1160         762  14.5  66.4   \n",
       "9353     181          641      92         1336        1122  16.2  71.2   \n",
       "9354      63          997      46         1102         617  13.7  68.2   \n",
       "9355      47         1257      41          898         323  13.7  48.8   \n",
       "9356      52         1116      43          958         489  11.8  56.0   \n",
       "\n",
       "          AH   CO_level  \n",
       "0     1.0741  Very High  \n",
       "1     1.0324  Very High  \n",
       "2     0.8244  Very High  \n",
       "3     1.0936  Very High  \n",
       "4     1.0979  Very High  \n",
       "...      ...        ...  \n",
       "9352  1.0919   Very low  \n",
       "9353  1.3013   Very low  \n",
       "9354  1.0611   Very low  \n",
       "9355  0.7606   Very low  \n",
       "9356  0.7743   Very low  \n",
       "\n",
       "[9357 rows x 15 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c515dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO_GT</th>\n",
       "      <th>PT08_S1_CO</th>\n",
       "      <th>C6H6_GT</th>\n",
       "      <th>PT08_S2_NMHC</th>\n",
       "      <th>Nox_GT</th>\n",
       "      <th>PT08_S3_Nox</th>\n",
       "      <th>NO2_GT</th>\n",
       "      <th>PT08_S4_NO2</th>\n",
       "      <th>PT08_S5_O3</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>CO_level</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>HOUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.9</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>50.6</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>2562.0</td>\n",
       "      <td>2342.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>74.7</td>\n",
       "      <td>1.0741</td>\n",
       "      <td>Very High</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>49.4</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>2477.0</td>\n",
       "      <td>2237.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>76.2</td>\n",
       "      <td>1.0324</td>\n",
       "      <td>Very High</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.2</td>\n",
       "      <td>1802.0</td>\n",
       "      <td>47.7</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2235.0</td>\n",
       "      <td>2452.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>52.8</td>\n",
       "      <td>0.8244</td>\n",
       "      <td>Very High</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.2</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>1369.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>2536.0</td>\n",
       "      <td>2386.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>72.6</td>\n",
       "      <td>1.0936</td>\n",
       "      <td>Very High</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>45.2</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>2338.0</td>\n",
       "      <td>2465.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>62.8</td>\n",
       "      <td>1.0979</td>\n",
       "      <td>Very High</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9352</th>\n",
       "      <td>NaN</td>\n",
       "      <td>993.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>604.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>848.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>66.4</td>\n",
       "      <td>1.0919</td>\n",
       "      <td>Very low</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9353</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>811.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>71.2</td>\n",
       "      <td>1.3013</td>\n",
       "      <td>Very low</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354</th>\n",
       "      <td>NaN</td>\n",
       "      <td>883.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>530.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>617.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>68.2</td>\n",
       "      <td>1.0611</td>\n",
       "      <td>Very low</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>NaN</td>\n",
       "      <td>818.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>473.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>48.8</td>\n",
       "      <td>0.7606</td>\n",
       "      <td>Very low</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>864.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>478.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.7743</td>\n",
       "      <td>Very low</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9357 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CO_GT  PT08_S1_CO  C6H6_GT  PT08_S2_NMHC  Nox_GT  PT08_S3_Nox  NO2_GT  \\\n",
       "0      11.9      2008.0     50.6        1980.0  1389.0        325.0   220.0   \n",
       "1      11.5      1918.0     49.4        1958.0  1358.0        335.0   190.0   \n",
       "2      10.2      1802.0     47.7        1924.0   748.0        356.0   192.0   \n",
       "3      10.2      1982.0     49.5        1959.0  1369.0        322.0   227.0   \n",
       "4      10.1      1956.0     45.2        1877.0  1389.0        347.0   255.0   \n",
       "...     ...         ...      ...           ...     ...          ...     ...   \n",
       "9352    NaN       993.0      2.3         604.0    85.0        848.0    65.0   \n",
       "9353    NaN      1122.0      6.0         811.0   181.0        641.0    92.0   \n",
       "9354    NaN       883.0      1.3         530.0    63.0        997.0    46.0   \n",
       "9355    NaN       818.0      0.8         473.0    47.0       1257.0    41.0   \n",
       "9356    NaN       864.0      0.8         478.0    52.0       1116.0    43.0   \n",
       "\n",
       "      PT08_S4_NO2  PT08_S5_O3     T    RH      AH   CO_level  MONTH  HOUR  \n",
       "0          2562.0      2342.0  12.4  74.7  1.0741  Very High     11    19  \n",
       "1          2477.0      2237.0  11.5  76.2  1.0324  Very High     11    20  \n",
       "2          2235.0      2452.0  13.7  52.8  0.8244  Very High     11    18  \n",
       "3          2536.0      2386.0  13.2  72.6  1.0936  Very High     11    18  \n",
       "4          2338.0      2465.0  15.5  62.8  1.0979  Very High     11    18  \n",
       "...           ...         ...   ...   ...     ...        ...    ...   ...  \n",
       "9352       1160.0       762.0  14.5  66.4  1.0919   Very low      3     4  \n",
       "9353       1336.0      1122.0  16.2  71.2  1.3013   Very low      3     4  \n",
       "9354       1102.0       617.0  13.7  68.2  1.0611   Very low      3     4  \n",
       "9355        898.0       323.0  13.7  48.8  0.7606   Very low      4     4  \n",
       "9356        958.0       489.0  11.8  56.0  0.7743   Very low      4     4  \n",
       "\n",
       "[9357 rows x 15 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    #Read UCI AQ Dataset\n",
    "    df = pd.read_csv(\"/Users/Gunnar/Documents/GitHub/UCI-Air-Quality-Analysis-Prediction/input/AirQualityUCI.csv\", parse_dates={'datetime': ['Date', 'Time']})\n",
    "\n",
    "    # 8443 values out of 9357 are -200. This coulmn is not needed thus dropping this coulumn .\n",
    "    df.drop('NMHC_GT', axis=1, inplace=True)\n",
    "\n",
    "    # In data we found a lot of -200 which seems to be a error. Removing those values and replacing with NaN i.e null \n",
    "    df.replace(to_replace= -200, value= np.NaN, inplace= True)\n",
    "\n",
    "    # Use fillna function to fill the missing values with an estimate value\n",
    "    col_list = df.columns[2:13]\n",
    "\n",
    "    for i in col_list:\n",
    "        df[i] = df[i].fillna(df[i].mean())\n",
    "        \n",
    "    #pandas datetimeindex docs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DatetimeIndex.html\n",
    "    #efficient way to extract year from string format date\n",
    "    df['MONTH'] = pd.DatetimeIndex(df['datetime']).month\n",
    "\n",
    "    df['HOUR'] = pd.DatetimeIndex(df['datetime']).hour\n",
    "    \n",
    "    df.drop(\"datetime\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8182f6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9357 entries, 0 to 9356\n",
      "Data columns (total 16 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   datetime      9357 non-null   datetime64[ns]\n",
      " 1   CO_GT         7674 non-null   float64       \n",
      " 2   PT08_S1_CO    9357 non-null   float64       \n",
      " 3   C6H6_GT       9357 non-null   float64       \n",
      " 4   PT08_S2_NMHC  9357 non-null   float64       \n",
      " 5   Nox_GT        9357 non-null   float64       \n",
      " 6   PT08_S3_Nox   9357 non-null   float64       \n",
      " 7   NO2_GT        9357 non-null   float64       \n",
      " 8   PT08_S4_NO2   9357 non-null   float64       \n",
      " 9   PT08_S5_O3    9357 non-null   float64       \n",
      " 10  T             9357 non-null   float64       \n",
      " 11  RH            9357 non-null   float64       \n",
      " 12  AH            9357 non-null   float64       \n",
      " 13  CO_level      9357 non-null   object        \n",
      " 14  MONTH         9357 non-null   int64         \n",
      " 15  HOUR          9357 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(12), int64(2), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2c280ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '19:00:00'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s1/k27_hssx5pv_k8zzl718j2280000gn/T/ipykernel_4655/127519076.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mcomparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlin_reg_pred_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn_reg_pred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/s1/k27_hssx5pv_k8zzl718j2280000gn/T/ipykernel_4655/127519076.py\u001b[0m in \u001b[0;36mmodel\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mpoly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mmy_old_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mmy_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_old_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/IronhackDA/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/IronhackDA/lib/python3.7/site-packages/sklearn/preprocessing/_polynomial.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/IronhackDA/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/IronhackDA/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/anaconda3/envs/IronhackDA/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '19:00:00'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jul 18 08:51:47 2018\n",
    "@author: Narayanan Abishek\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jul 18 08:51:47 2018\n",
    "@author: Narayanan Abishek\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers.normalization import BatchNormalization, regularizers\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "lamda = 0.01\n",
    "\n",
    "#original dataset\n",
    "def get_data():\n",
    "    # Preprocessing\n",
    "    # - 2 Deleting and rearranging columns\n",
    "    # - 3 Working with data types (set the correct type)\n",
    "    # - 4 Filtering data\n",
    "    # - 5 Removing duplicates\n",
    "    # - 6 Correcting typos\n",
    "    # - 7 Conditional formatting\n",
    "    # - 8 Replace missing values   - 1 Standardize column names\n",
    "\n",
    "    #Read UCI AQ Dataset\n",
    "    df = pd.read_csv(\"/Users/Gunnar/Documents/GitHub/UCI-Air-Quality-Analysis-Prediction/input/AirQualityUCI.csv\", parse_dates={'datetime': ['Date', 'Time']})\n",
    "\n",
    "    # 8443 values out of 9357 are -200. This coulmn is not needed thus dropping this coulumn .\n",
    "    df.drop('NMHC_GT', axis=1, inplace=True)\n",
    "\n",
    "    # In data we found a lot of -200 which seems to be a error. Removing those values and replacing with NaN i.e null \n",
    "    df.replace(to_replace= -200, value= np.NaN, inplace= True)\n",
    "\n",
    "    # Use fillna function to fill the missing values with an estimate value\n",
    "    col_list = df.columns[2:13]\n",
    "\n",
    "    for i in col_list:\n",
    "        df[i] = df[i].fillna(df[i].mean())\n",
    "        \n",
    "    #pandas datetimeindex docs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DatetimeIndex.html\n",
    "    #efficient way to extract year from string format date\n",
    "    df['MONTH'] = pd.DatetimeIndex(df['datetime']).month\n",
    "\n",
    "    df['HOUR'] = pd.DatetimeIndex(df['datetime']).hour\n",
    "    \n",
    "    df.drop(\"datetime\", axis = 1)\n",
    "\n",
    "    return airquality_df\n",
    "    \n",
    "    \n",
    "#feature scaling for the gradient descent to converge faster\n",
    "def feature_scaling(x):\n",
    "    \n",
    "    X_mean = np.mean(x,axis=0)\n",
    "    X_sigma = np.std(x,axis=0)\n",
    "    X = np.divide((x - X_mean),X_sigma)\n",
    "    return X\n",
    "\n",
    "#initializing the weights and bias\n",
    "def initialize_params_linear():\n",
    "    \n",
    "    w = tf.Variable(tf.random.truncated_normal([90, 1], mean=0.0, stddev=1.0, dtype=tf.float64))\n",
    "    b = tf.Variable(tf.zeros(1, dtype = tf.float64))\n",
    "    return w,b\n",
    "\n",
    "def calc(X,Y,w,b):\n",
    "    \n",
    "    predictions = tf.add(tf.matmul(X,w),b)\n",
    "    regularizer = tf.nn.l2_loss(w)\n",
    "    error = tf.reduce_mean(tf.square(Y-predictions) + (lamda * regularizer) )\n",
    "    return predictions,error #returns tensor\n",
    "\n",
    "def linear_regression_simple(train_X,train_Y,val_X,val_Y,test_X,test_Y,w,b,learning_rate = 0.5,num_epochs=7500):\n",
    "    \n",
    "    \n",
    "    predictions,cost = calc(train_X,train_Y,w,b) #yhat and cost\n",
    "    points = [[],[]] #to store train_set_cost\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) \n",
    "    #initialize the optimizer before the global initialization, since optimizer creates variables leads in memory leak\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        \n",
    "        sess.run(init)\n",
    "        \n",
    "        for i in list(range(num_epochs)):\n",
    "           \n",
    "            sess.run(optimizer)\n",
    "            if i%10 == 0:\n",
    "                points[0].append(i+1) #iteration\n",
    "                points[1].append(sess.run(cost)) #cost\n",
    "\n",
    "        pred = predictions.eval() #to convert predictions <tensor> into pred <numpy array>\n",
    "        \n",
    "        valid_predictions,valid_cost = calc(val_X,val_Y,w,b) #yhat, cost for validation set\n",
    "    \n",
    "        val_Y_pred = valid_predictions.eval() #to convert valid_predictions<tensor> into valid_pred<numpy>\n",
    "                \n",
    "        plt.figure()\n",
    "        plt.plot(points[0], points[1], 'r--') #red marking\n",
    "        plt.axis = (0,num_epochs,0,20)\n",
    "        plt.show()\n",
    "        \n",
    "        test_predictions,test_cost = calc(test_X,test_Y,w,b)\n",
    "        test_Y_pred = test_predictions.eval()\n",
    "        \n",
    "   \n",
    "    print(\"\\nTraining set accuracy: \\n\")\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(train_Y,pred))  \n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(train_Y,pred))  \n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(train_Y,pred)))\n",
    "        \n",
    "    print(\"\\nValidation set accuracy: \\n\")\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(val_Y, val_Y_pred))  \n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(val_Y, val_Y_pred))  \n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(val_Y, val_Y_pred)))\n",
    "        \n",
    "    print(\"\\nTesting set accuracy: \\n\")\n",
    "    \n",
    "   \n",
    "    \n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(test_Y, test_Y_pred))  \n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(test_Y, test_Y_pred))  \n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_Y, test_Y_pred)))\n",
    "\n",
    "    print(\"\\nActual Train Value: \", train_Y[82], \"Predicted Train value: \", pred[82])\n",
    "    print(\"\\nActual Validation Value: \", val_Y[834], \"Predicted Validation value: \", val_Y_pred[834])\n",
    "    print(\"\\nActual Test Value: \", test_Y[948], \"Predicted Test value: \", test_Y_pred[948])\n",
    "    \n",
    "    return test_Y_pred\n",
    "\n",
    "def nn_regression(final_train_X,train_y,final_val_X,val_y,final_test_X,test_y):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(90, input_dim = 90,kernel_initializer='normal',kernel_regularizer = regularizers.l2(0.00025)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(40,kernel_initializer='normal',kernel_regularizer = regularizers.l2(0.00025)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(40,kernel_initializer='normal',kernel_regularizer = regularizers.l2(0.00025)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(40,kernel_initializer='normal',kernel_regularizer = regularizers.l2(0.00025)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1,kernel_initializer = 'normal',kernel_regularizer = regularizers.l2(0.00025)))\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "    \n",
    "    trained_model = model.fit(final_train_X, train_y, epochs = 200,validation_data=(final_val_X,val_y))\n",
    "    \n",
    "    y_pred = model.predict(final_test_X)\n",
    "    \n",
    "    print(\"\\nTesting set accuracy: \\n\")\n",
    "     \n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(test_y, y_pred))  \n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(test_y, y_pred))  \n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_y, y_pred)))\n",
    "\n",
    "    print(\"\\nActual Test Value: \", test_y[500], \"Predicted Test value: \", y_pred[500])\n",
    "    \n",
    "\n",
    "    plt.plot(trained_model.history['loss'], color = 'red', label = 'Train data loss')\n",
    "    plt.plot(trained_model.history['val_loss'], color = 'blue', label = 'Validation data loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def comparison(test_y,lin_reg_pred_y,nn_reg_pred_y):\n",
    "    \n",
    "    plt.plot(np.abs(test_y - lin_reg_pred_y), color = 'red', label = 'Difference between Test data and linear regression predicted values')\n",
    "    plt.plot(np.abs(test_y - nn_reg_pred_y), color = 'blue', label = 'Difference between Test data and DNN regressor predicted values')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def model():\n",
    "    \n",
    "    my_df = get_data()\n",
    "    w,b = initialize_params_linear()\n",
    "    \n",
    "    x = my_df.iloc[:,1:13]\n",
    "    y = my_df.iloc[:,13]\n",
    "    \n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    \n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    \n",
    "    my_old_X = poly.fit_transform(x)\n",
    "    \n",
    "    my_X = np.nan_to_num(my_old_X)    \n",
    "    \n",
    "    X = np.reshape(np.array(my_X),(my_X.shape[0],my_X.shape[1]))\n",
    "    Y = np.reshape(np.array(y),(y.shape[0],1))\n",
    "        \n",
    "    from sklearn.model_selection import train_test_split  \n",
    "        \n",
    "    train_x, val_x, train_y,val_y = train_test_split(X, Y, test_size=0.2, random_state=0) \n",
    "    \n",
    "    train_x, test_x, train_y,test_y = train_test_split(train_x,train_y, test_size=0.2, random_state=0) \n",
    " \n",
    "    train_X = np.delete(train_x, 0, axis=1)\n",
    "    final_train_X = feature_scaling(train_X)\n",
    "    \n",
    "    val_X = np.delete(val_x, 0, axis=1)\n",
    "    final_val_X = feature_scaling(val_X)\n",
    "    \n",
    "    test_X = np.delete(test_x, 0, axis=1)\n",
    "    final_test_X = feature_scaling(test_X)\n",
    "    \n",
    "        \n",
    "    print(\"Shape of train-X-data:\",final_train_X.shape)\n",
    "    print(\"Shape of train-Y-data:\",train_y.shape)\n",
    "\n",
    "    print(\"Shape of val-X-data:\",final_val_X.shape)\n",
    "    print(\"Shape of val-Y-data:\",val_y.shape)\n",
    "    \n",
    "    print(\"Shape of test-X-data:\",final_test_X.shape)\n",
    "    print(\"Shape of test-Y-data:\",test_y.shape)\n",
    "    \n",
    "    lin_reg_pred_y = linear_regression_simple(final_train_X,train_y,final_val_X,val_y,final_test_X,test_y,w,b)\n",
    "    nn_reg_pred_y = nn_regression(final_train_X,train_y,final_val_X,val_y,final_test_X,test_y)\n",
    "    \n",
    "    comparison(test_y,lin_reg_pred_y,nn_reg_pred_y)\n",
    "\n",
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb43bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
